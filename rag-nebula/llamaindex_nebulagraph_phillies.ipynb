{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d337ee",
   "metadata": {},
   "source": [
    "# Querying Philadelphia Phillies with LlamaIndex and NebulaGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e63d85",
   "metadata": {},
   "source": [
    "## 安装依赖和载入环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c37b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U llama_index wikipedia llama-index-llms-openai-like llama-index-readers-wikipedia llama-index-readers-youtube-transcript llama-index-graph-stores-nebula llama-index-llms-openai ipython-ngql nebula3-python pyvis networkx youtube_transcript_api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01202746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(os.environ[\"OPENAI_API_KEY\"])\n",
    "print(os.environ[\"OPENAI_API_BASE\"])\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"rag.log\",\n",
    "    filemode=\"w\",\n",
    "    format=\"%(name)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc97cc",
   "metadata": {},
   "source": [
    "## 连接到图数据库，并新建图空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eadf711",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GRAPHD_HOST\"] = \"127.0.0.1\"\n",
    "os.environ[\"NEBULA_USER\"] = \"root\"\n",
    "os.environ[\"NEBULA_PASSWORD\"] = \"nebula\" \n",
    "os.environ[\"NEBULA_ADDRESS\"] = \"127.0.0.1:9669\"  \n",
    "\n",
    "%reload_ext ngql\n",
    "connection_string = f\"--address {os.environ['GRAPHD_HOST']} --port 9669 --user root --password {os.environ['NEBULA_PASSWORD']}\"\n",
    "%ngql {connection_string}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a597c-f96b-4ed3-b688-cde14bd09619",
   "metadata": {},
   "source": [
    "创建一个名为 phillies_rag 的图空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5892a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ngql CREATE SPACE IF NOT EXISTS phillies_rag(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1742de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ngql SHOW SPACES;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a369d-6904-4238-9e5f-9056b9c1a01d",
   "metadata": {},
   "source": [
    "在新的图空间中创建标签、边和标签索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ngql\n",
    "USE phillies_rag;\n",
    "CREATE TAG IF NOT EXISTS entity(name string);\n",
    "CREATE EDGE IF NOT EXISTS relationship(relationship string);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879761b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ngql CREATE TAG INDEX IF NOT EXISTS entity_index ON entity(name(256));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820bf6db-d0bc-4f74-b352-bfdc77ef2ebd",
   "metadata": {},
   "source": [
    "构建下 NebulaGraphStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.nebula import NebulaGraphStore\n",
    "\n",
    "space_name = \"phillies_rag\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\"relationship\"]\n",
    "tags = [\"entity\"]\n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208852a5",
   "metadata": {},
   "source": [
    "## 加载数据并创建 KG 索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf4050-c50c-4fab-8912-93f6cedfe803",
   "metadata": {},
   "source": [
    "是时候加载数据了。我们的源数据来自 Philadelphia Phillies 的维基百科页面和一个关于 Trea Turner 在 2023 年 8 月收到 standing ovation 的 YouTube 视频。\n",
    "\n",
    "为了节省时间和成本，我们先检查下本地 storage_context 来加载 KG 索引。如果存在索引，我们就加载索引。如果不存在索引（例如初次访问应用程序时），我们需要加载这两个源文档（上文提到的维基百科页面和 YouTube 视频），再构建 KG 索引，并在项目 root 目录的本地 storage_graph 中持久化地存储 doc、index 和 vector。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d650799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index import KnowledgeGraphIndex\n",
    "# from llama_index.graph_stores import SimpleGraphStore\n",
    "# from llama_index import download_loader\n",
    "# from llama_index.llms import OpenAI\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "# define LLM\n",
    "Settings.llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding()\n",
    "Settings.chunk_size = 512\n",
    "\n",
    "# test if model is ready\n",
    "response = Settings.llm.chat([ChatMessage(role=\"user\", content=\"Hello\")])\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb727e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex\n",
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "try:\n",
    "    documents = SimpleDirectoryReader('./storage_graph').load_data()\n",
    "    # kg_index = load_index_from_storage(\n",
    "    #     storage_context=storage_context,\n",
    "    #     service_context=service_context,\n",
    "    #     max_triplets_per_chunk=15,\n",
    "    #     space_name=space_name,\n",
    "    #     edge_types=edge_types,\n",
    "    #     rel_prop_names=rel_prop_names,\n",
    "    #     tags=tags,\n",
    "    #     verbose=True,\n",
    "    # )\n",
    "    kg_index = KnowledgeGraphIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context,\n",
    "        max_triplets_per_chunk=15,\n",
    "        space_name=space_name,\n",
    "        edge_types=edge_types,\n",
    "        rel_prop_names=rel_prop_names,\n",
    "        tags=tags,\n",
    "        verbose=True,\n",
    "    )\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False\n",
    "\n",
    "if not index_loaded:\n",
    "    print(\"Load data and persist index\")\n",
    "    loader = WikipediaReader()\n",
    "    wiki_documents = loader.load_data(pages=['Philadelphia Phillies'], auto_suggest=False)\n",
    "    print(f'Loaded {len(wiki_documents)} documents')\n",
    "\n",
    "    youtube_loader = YoutubeTranscriptReader()\n",
    "    youtube_documents = youtube_loader.load_data(ytlinks=['https://www.youtube.com/watch?v=k-HTQ8T7oVw'])    \n",
    "    print(f'Loaded {len(youtube_documents)} YouTube documents')\n",
    "\n",
    "    kg_index = KnowledgeGraphIndex.from_documents(\n",
    "        documents=wiki_documents + youtube_documents,\n",
    "        storage_context=storage_context,\n",
    "        max_triplets_per_chunk=15,\n",
    "        space_name=space_name,\n",
    "        edge_types=edge_types,\n",
    "        rel_prop_names=rel_prop_names,\n",
    "        tags=tags,\n",
    "        include_embeddings=True,\n",
    "    )\n",
    "    \n",
    "    kg_index.storage_context.persist(persist_dir='./storage_graph')\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb396248-50ec-4833-84e4-982dbcf14cf6",
   "metadata": {},
   "source": [
    "在构建 KG 索引时，需要注意以下几点：\n",
    "\n",
    "\r\n",
    "max_triplets_per_chunk：每个块提取三元组的最大数。将其设置为 15，可覆盖大多数（可能不是所有）块中的内\n",
    "\n",
    "\r\n",
    "\r\n",
    "include_embeddings：说明创建 KG 索引时，是否包含数据的 Embedding。Embedding 是一种将文本数据表示为数据语义的向量法。它们通常用来让模型理解不同文本片段之间的语义相似性。当设置 include_embeddings=True 时，KnowledgeGraphIndex 会在索引中包含这些嵌入。当你想在知识图谱上执行语义搜索时，include_embeddings=True 会很有用，因为 Embedding 可用来找到与查询在语义上相似的节点和边。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6769d53",
   "metadata": {},
   "source": [
    "## Query with Text2Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88224a-65e4-4bb9-9e89-2d8b4951807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import KnowledgeGraphQueryEngine\n",
    "from llama_index.core import StorageContext\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021f25d-1832-4857-af90-f4c915b196d3",
   "metadata": {},
   "source": [
    "### 图探索的方法 1：KG 基于向量的检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff87f62-96a2-4bae-8cd5-baa26b407547",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = kg_index.as_query_engine()\n",
    "response = query_engine.query(\"Tell me about some of the facts of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75c3b7-a6e6-496e-b63e-e6b0a0ecc57a",
   "metadata": {},
   "source": [
    "query_engine = kg_index.as_query_engine() 这种方法通过向量相似性查找 KG 实体，获取连接的文本块，并选择性探索关系。是 LlamaIndex 基于索引构建的默认查询方式。它非常简单、开箱即用，不用额外的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fef5c-9dd0-4445-9613-96abbb73804b",
   "metadata": {},
   "source": [
    "### 图探索的方法 2：KG 基于关键词的检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d02c4f-fc48-4f92-8bbc-148021eefc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_keyword_query_engine = kg_index.as_query_engine(\n",
    "    # setting to false uses the raw triplets instead of adding the text from the corresponding nodes\n",
    "    include_text=False,\n",
    "    retriever_mode=\"keyword\",\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "response = kg_keyword_query_engine.query(\"Tell me about some of the facts of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225eaf21-dbf1-4b64-8b05-fb32d51af7e1",
   "metadata": {},
   "source": [
    "这个查询用了关键词来检索相关的 KG 实体，来获取连接的文本块，并选择性地探索关系以获取更多的上下文。\n",
    "\n",
    "参数 retriever_mode=\"keyword\" 指定了本次检索采用关键词形式。\n",
    "\n",
    "include_text=False：查询引擎只用原生三元组进行查询，查询不包含对应节点的文本信息；\n",
    "\n",
    "response_mode=\"tree_summarize\"：返回结果（响应形式）是知识图谱的树结构的总结。这个树以递归方式构建，查询作为根节点，最相关的答案作为叶节点。tree_summarize 响应模式对于总结性任务非常有用，比如：提供某个话题的高度概括，或是回答某个需要考虑周全的问题。当然，它还可以生成更复杂的响应，比如：解释某个事物发生的真实原因，或者解释某个过程涉及了哪些步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ea07ea-f14d-4fd9-b038-9ebd8e709623",
   "metadata": {},
   "source": [
    "### 图探索方法 3：KG 混合检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8410735",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_query_engine = kg_index.as_query_engine(\n",
    "    include_text=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=3,\n",
    "    explore_global_knowledge=True,\n",
    ")\n",
    "\n",
    "response = hybrid_query_engine.query(\"Tell me about Bryce Harper.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6fae5d-4c0a-4cb9-816d-8cca6ce6ff9c",
   "metadata": {},
   "source": [
    "通过设定 embedding_mode=\"hybrid\"，指定查询引擎为基于向量的检索和基于关键词的检索二者的混合方式，从知识图谱中检索信息，并进行去重。KG 混合检索方式不仅使用关键词找到相关的三元组，它也使用基于向量的检索来找到基于语义相似性的相似三元组。所以，本质上，混合模式结合了关键词搜索和语义搜索，并利用这两种方法的优势来提高搜索结果的准确性和相关性。\n",
    "\n",
    "include_text=True：同上文的字段一样，用来指定是否包含节点的文本信息；\r\n",
    "\r\n",
    "similarity_top_k=3：Top K 设定，它将根据 Embedding 检索出最相似结果的前三个结果。你可以根据你的使用场景弹性地调整这个值；\r\n",
    "\r\n",
    "explore_global_knowledge=True：指定查询引擎是否要考虑知识图谱的全局上下文来检索信息。当设置 explore_global_knowledge=True时，查询引擎不会将其搜索限制在本地上下文（即，一个节点的直接邻居），而是会考虑知识图谱的更广泛的全局上下文。当你想检索与查询不直接相关，但在该知识图谱的更大上下文中有关的信息时，这可能很有用。\r\n",
    "\r\n",
    "基于关键词的检索和混合检索二者主要区别，在于我们从知识图谱中检索信息的方法：基于关键词的检索使用关键词方法，而混合检索使用结合 Embedding 和关键词的混合方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a36fc-5171-4925-b304-4dc5e7b792b9",
   "metadata": {},
   "source": [
    "### 绘制图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b199aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ngql\n",
    "MATCH (p:`entity`)-[e:relationship]->(m:`entity`)\n",
    "  WHERE p.`entity`.`name` == 'Phillies'\n",
    "RETURN p, e, m LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea34d91-b4dd-46b5-8f7f-8ed24e33bf28",
   "metadata": {},
   "source": [
    "我们可以试一下查询引擎是否有正确使用到图中的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d83dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Tell about Ryan howard.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ngql \n",
    "MATCH (p:`entity`)-[r:`relationship`]->(q:`entity`)\n",
    "WHERE p.`entity`.`name` == 'Ryan howard' \n",
    "RETURN p, r, q;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110773e3",
   "metadata": {},
   "source": [
    "## 使用向量索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f61f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "loader = WikipediaReader()\n",
    "wiki_documents = loader.load_data(pages=['Philadelphia Phillies'], auto_suggest=False)\n",
    "print(f'Loaded {len(wiki_documents)} documents')\n",
    "\n",
    "youtube_loader = YoutubeTranscriptReader()\n",
    "youtube_documents = youtube_loader.load_data(ytlinks=['https://www.youtube.com/watch?v=k-HTQ8T7oVw'])    \n",
    "print(f'Loaded {len(youtube_documents)} YouTube documents')\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(wiki_documents + youtube_documents)\n",
    "vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "response = vector_query_engine.query(\"Tell me about Bryce Harper.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a51d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vector_query_engine.query(\"How did the standing ovation Trey Turner received change his season?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9eb77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vector_query_engine.query(\"Tell me about some of the facts of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb291e",
   "metadata": {},
   "source": [
    "## Create CustomRetriever to combine vector index and KG index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import QueryBundle\n",
    "from llama_index.schema import NodeWithScore\n",
    "from llama_index.retrievers import BaseRetriever, VectorIndexRetriever, KGTableRetriever\n",
    "from typing import List\n",
    "\n",
    "class CustomRetriever(BaseRetriever):\n",
    "    \"\"\"Custom retriever that performs both Vector search and Knowledge Graph search\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_retriever: VectorIndexRetriever,\n",
    "        kg_retriever: KGTableRetriever,\n",
    "        mode: str = \"OR\",\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "\n",
    "        self._vector_retriever = vector_retriever\n",
    "        self._kg_retriever = kg_retriever\n",
    "        if mode not in (\"AND\", \"OR\"):\n",
    "            raise ValueError(\"Invalid mode.\")\n",
    "        self._mode = mode\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "\n",
    "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
    "        kg_nodes = self._kg_retriever.retrieve(query_bundle)\n",
    "\n",
    "        vector_ids = {n.node.node_id for n in vector_nodes}\n",
    "        kg_ids = {n.node.node_id for n in kg_nodes}\n",
    "\n",
    "        combined_dict = {n.node.node_id: n for n in vector_nodes}\n",
    "        combined_dict.update({n.node.node_id: n for n in kg_nodes})\n",
    "\n",
    "        if self._mode == \"AND\":\n",
    "            retrieve_ids = vector_ids.intersection(kg_ids)\n",
    "        else:\n",
    "            retrieve_ids = vector_ids.union(kg_ids)\n",
    "\n",
    "        retrieve_nodes = [combined_dict[rid] for rid in retrieve_ids]\n",
    "        return retrieve_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import get_response_synthesizer\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers import VectorIndexRetriever, KGTableRetriever\n",
    "\n",
    "# create custom retriever\n",
    "vector_retriever = VectorIndexRetriever(index=vector_index)\n",
    "kg_retriever = KGTableRetriever(\n",
    "    index=kg_index, retriever_mode=\"keyword\", include_text=False\n",
    ")\n",
    "custom_retriever = CustomRetriever(vector_retriever, kg_retriever)\n",
    "\n",
    "# create response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    service_context=service_context,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058aba5",
   "metadata": {},
   "source": [
    "## Create 7 query engines and run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5faed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KG vector-based entity retrieval\n",
    "kg_query_engine = kg_index.as_query_engine()\n",
    "\n",
    "# KG keyword-based entity retrieval\n",
    "kg_keyword_query_engine = kg_index.as_query_engine(\n",
    "    # setting to false uses the raw triplets instead of adding the text from the corresponding nodes\n",
    "    include_text=False,\n",
    "    retriever_mode=\"keyword\",\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "\n",
    "# KG hybrid entity retrieval\n",
    "kg_hybrid_query_engine = kg_index.as_query_engine(\n",
    "    include_text=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=3,\n",
    "    explore_global_knowledge=True,\n",
    ")\n",
    "\n",
    "# Raw vector index retrieval\n",
    "vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "# Custom combo query engine\n",
    "custom_query_engine = RetrieverQueryEngine(\n",
    "    retriever=custom_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "# using KnowledgeGraphQueryEngine\n",
    "from llama_index.query_engine import KnowledgeGraphQueryEngine\n",
    "\n",
    "kgqe_query_engine = KnowledgeGraphQueryEngine(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# using KnowledgeGraphRAGRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers import KnowledgeGraphRAGRetriever\n",
    "\n",
    "graph_rag_retriever = KnowledgeGraphRAGRetriever(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "kg_rag_query_engine = RetrieverQueryEngine.from_args(\n",
    "    graph_rag_retriever, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07739d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_query_engine.query(\"Tell me about Bryce Harper.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99889510",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_keyword_query_engine.query(\"Tell me about Bryce Harper.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_hybrid_query_engine.query(\"Tell me about Bryce Harper.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vector_query_engine.query(\"Tell me about Bryce Harper.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d51472",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = custom_query_engine.query(\"Tell me about Bryce Harper.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca895ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kgqe_query_engine.query(\"Tell me about Bryce Harper.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_rag_query_engine.query(\"Tell me about Bryce Harper.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_query_engine.query(\"How did the standing ovation Trey Turner received change his season?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_keyword_query_engine.query(\"How did the standing ovation Trey Turner received change his season?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_hybrid_query_engine.query(\"How did the standing ovation Trey Turner received change his season?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vector_query_engine.query(\"How did the standing ovation Trey Turner received change his season?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aeefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = custom_query_engine.query(\"How did the standing ovation Trey Turner received change his season?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e10a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kgqe_query_engine.query(\"How did the standing ovation Trey Turner received change his season?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f64284",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_rag_query_engine.query(\"How did the standing ovation Trey Turner received change his season?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_query_engine.query(\"Tell me some facts about the current stadium of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17189425",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_keyword_query_engine.query(\"Tell me some facts about the current stadium of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d84c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_hybrid_query_engine.query(\"Tell me some facts about the current stadium of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vector_query_engine.query(\"Tell me some facts about the current stadium of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = custom_query_engine.query(\"Tell me some facts about the current stadium of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kgqe_query_engine.query(\"Tell me some facts about the current stadium of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72af9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kg_rag_query_engine.query(\"Tell me some facts about the current stadium of Philadelphia Phillies.\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565e627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-on-s3",
   "language": "python",
   "name": "rag-on-s3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
